# In-Depth Study Notes: Managing Azure Security

## Managing User Permissions to Azure Resources

1. Managing User Permissions to Azure Resources
Objective:
    ‚Ä¢ Implement least-privilege access by grouping users based on attributes (like city = Toronto) and assigning appropriate roles at the resource level.
    ‚Ä¢ Ensure dynamic scaling of permissions as users meet group criteria.
Why It Matters:
    ‚Ä¢ Prevents over-provisioning of access
    ‚Ä¢ Supports dynamic environments (e.g., hiring in Toronto auto-adds users to the right group with right access)
    ‚Ä¢ Complies with Zero Trust principle of role-based access controls (RBAC)
Portal Steps:
    1. Create Dynamic Group:
        ‚óã Azure Active Directory > Groups > + New group
        ‚óã Group type: Security
        ‚óã Group name: Toronto_Users
        ‚óã Membership type: Dynamic User
        ‚óã Add owner: Abu Adachi
        ‚óã Add dynamic rule: Property = city, Operator = equals, Value = Toronto
    2. Add User:
        ‚óã Azure AD > Users > + New user
        ‚óã Set Name: Julio Chavez, UPN: jchavez@yourdomain.com
        ‚óã After creation, open profile ‚Üí Edit properties ‚Üí Set City = Toronto
    3. Assign Role to Group:
        ‚óã Resource Group > App1 > IAM > Add Role Assignment
        ‚óã Role: Storage Blob Data Reader
        ‚óã Assign to: User, group, or service principal ‚Üí Select Toronto_Users
PowerShell:
# Create user
New-AzADUser -DisplayName "Julio Chavez" -UserPrincipalName "jchavez@yourdomain.com" \
  -MailNickname "jchavez" -PasswordProfile @{Password="Password123!"; ForceChangePasswordNextLogin=$true} \
  -AccountEnabled $true -UsageLocation "CA"
# Set user city
Update-MgUser -UserId "jchavez@yourdomain.com" -City "Toronto"
# Create dynamic group
$rule = '(user.city -eq "Toronto")'
New-MgGroup -DisplayName "Toronto_Users" -MailEnabled:$false -MailNickname "torontousers" \
  -SecurityEnabled:$true -GroupTypes @("DynamicMembership") \
  -MembershipRule $rule -MembershipRuleProcessingState "On"
# Assign role
$group = Get-AzADGroup -DisplayName "Toronto_Users"
New-AzRoleAssignment -ObjectId $group.Id -RoleDefinitionName "Storage Blob Data Reader" -ResourceGroupName "App1"
Azure CLI:
az ad user create --display-name "Julio Chavez" \
  --user-principal-name jchavez@yourdomain.com \
  --password "Password123!" --force-change-password-next-login true
az rest --method patch --uri "https://graph.microsoft.com/v1.0/users/jchavez@yourdomain.com" \
  --headers "Content-Type=application/json" \
  --body '{"city":"Toronto"}'
az ad group create --display-name "Toronto_Users" --mail-nickname "torontousers"
az rest --method patch --uri "https://graph.microsoft.com/v1.0/groups/<groupId>" \
  --headers "Content-Type=application/json" \
  --body '{ "groupTypes":["DynamicMembership"], "membershipRuleProcessingState":"On", "membershipRule":"(user.city -eq \"Toronto\")" }'
az role assignment create --assignee <group-object-id> --role "Storage Blob Data Reader" --resource-group App1



## Defining Custom RBAC Roles
    ‚Ä¢ Defining Custom RBAC Roles
Objective:
Create and assign a custom RBAC role that provides:
        ‚óã Full VM management permissions
        ‚óã Read-only access to Blob storage
        ‚óã Scope: Resource group App1


Security Context / Why We Do This:
        ‚óã Custom roles offer granular control when built-in roles don‚Äôt match the exact operational needs.
        ‚óã Helps meet least privilege and compliance mandates.
    ‚Ä¢ Limits lateral movement potential by restricting scope to App1 only.

Key Concepts from Video:
    ‚Ä¢ Combine multiple actions into a single role: VM management + Blob read
    ‚Ä¢ Ensure the assignable scope is set to avoid global role misuse
    ‚Ä¢ Roles must follow JSON schema (or portal equivalent)

Portal Steps:
    1. Go to Subscriptions > Choose subscription > Access control (IAM) > + Add > Add custom role
        ‚óã Name: Custom VM Management
        ‚óã Start from scratch
        ‚óã Permissions:
            ¬ß Add: Microsoft.Compute/*
            ¬ß Add: Microsoft.Storage/storageAccounts/blobServices/containers/blobs/read
        ‚óã Assignable scope: /subscriptions/<subId>/resourceGroups/App1
        ‚óã Click Review + create
    2. Assign Role to User
        ‚óã Go to Resource groups > App1 > Access control (IAM)
        ‚óã Click + Add > Add role assignment
        ‚óã Filter by: Custom VM Management
        ‚óã Assign to: Abu

PowerShell:
# Create custom role definition
$customRole = @{
  Name = "Custom VM Management"
  Id = (New-Guid).Guid
  IsCustom = $true
  Description = "VM admin and blob read"
  Actions = @(
    "Microsoft.Compute/*",
    "Microsoft.Storage/storageAccounts/blobServices/containers/blobs/read"
  )
  NotActions = @()
  DataActions = @()
  NotDataActions = @()
  AssignableScopes = @("/subscriptions/<subId>/resourceGroups/App1")
}
$roleJson = $customRole | ConvertTo-Json -Depth 10
$rolePath = "./customRole.json"
$roleJson | Out-File $rolePath
New-AzRoleDefinition -InputFile $rolePath
# Assign role
$user = Get-AzADUser -DisplayName "Abu"
New-AzRoleAssignment -ObjectId $user.Id -RoleDefinitionName "Custom VM Management" -Scope "/subscriptions/<subId>/resourceGroups/App1"

Azure CLI:
# Create custom role definition
cat <<EOF > custom-role.json
{
  "Name": "Custom VM Management",
  "IsCustom": true,
  "Description": "VM admin and blob read",
  "Actions": [
    "Microsoft.Compute/*",
    "Microsoft.Storage/storageAccounts/blobServices/containers/blobs/read"
  ],
  "AssignableScopes": ["/subscriptions/<subId>/resourceGroups/App1"]
}
EOF
az role definition create --role-definition custom-role.json
# Assign role
userId=$(az ad user show --id abu@yourdomain.com --query id -o tsv)
az role assignment create \
  --assignee $userId \
  --role "Custom VM Management" \
  --scope "/subscriptions/<subId>/resourceGroups/App1"


##  Configuring Conditional Access Policies


3. Configuring Conditional Access Policies
Objective:
    ‚Ä¢ Protect cloud applications using identity-based conditions and contextual signals
    ‚Ä¢ Create policy for app "Mobile Xpense" requiring MFA, Android platform, from trusted subnet
Why It Matters:
    ‚Ä¢ Prevents unauthorized access from unknown devices/locations
    ‚Ä¢ Combats credential theft via phishing by enforcing MFA
    ‚Ä¢ Meets compliance requirements (e.g., location-aware access)
Security Context / Why We Do This:
    ‚Ä¢ Conditional Access enforces Zero Trust principles: never trust, always verify.
    ‚Ä¢ Ensures only compliant devices from trusted networks can access sensitive apps.
    ‚Ä¢ Combines user context, device state, and network location to control access.
    
Portal Steps:
    1. Create named location:
        ‚óã Azure AD > Security > Named Locations > Add IP range
        ‚óã Name: Headquarters Europe
        ‚óã IP Range: 192.168.1.0/24 ‚Üí Mark as trusted
    2. Create Conditional Access Policy:
        ‚óã Azure AD > Security > Conditional Access > New Policy
        ‚óã Name: Allow Access to Mobile Xpense
        ‚óã Assign to: All Users
        ‚óã Cloud App: Mobile Xpense
        ‚óã Conditions:
            ¬ß Device Platform: Android
            ¬ß Locations: Include Headquarters Europe
        ‚óã Access Control: Grant access ‚Üí Require MFA
        ‚óã Enable Policy: On
PowerShell:
Connect-MgGraph -Scopes "Policy.ReadWrite.ConditionalAccess"
New-MgConditionalAccessNamedLocation -DisplayName "Headquarters Europe" `
  -IpRange @{Ranges="192.168.1.0/24"; IsTrusted=$true}
New-MgConditionalAccessPolicy -DisplayName "Allow Access to Mobile Xpense" `
  -State "enabled" `
  -Conditions @{
      Users = @{Include = @("All")}
      Platforms = @{Include = @("android")}
      Locations = @{Include = @("<location-id>")}
    } `
  -GrantControls @{BuiltInControls = @("mfa")} `
  -Applications @{IncludeApplications = @("<mobile-xpense-app-id>")}
Azure CLI:
    ‚ùå Not available in az CLI directly. Use Microsoft Graph CLI or REST API.

## Assigning Permissions to Azure VMs

4. Assigning Permissions to Azure VMs
Objective:
    ‚Ä¢ Configure a system-assigned managed identity on a VM (WinSrv2019-2)
    ‚Ä¢ Grant it the Storage Blob Data Reader role
    ‚Ä¢ Allow the VM to securely access storage blobs in the App1 resource group

Security Context / Why We Do This:
    ‚Ä¢ Avoids use of hard-coded secrets or credentials in scripts and apps
    ‚Ä¢ Enforces least privilege via role-based access control (RBAC)
    ‚Ä¢ Enables secure service-to-service authentication within Azure
    ‚Ä¢ Managed identities are automatically rotated and protected by Azure AD

Key Concepts from Video:
    ‚Ä¢ System-assigned identity is bound to the lifecycle of the VM. When the VM is deleted, the identity is automatically removed.
    ‚Ä¢ Assigning roles to this identity enables secure access to Azure resources, like storage accounts, without embedding credentials.
    ‚Ä¢ In this scenario, the identity will be used to access blobs, which can contain app configurations, logs, or other shared data.

Portal Steps:
    1. Enable System-Assigned Identity
        ‚óã Go to Virtual Machines > Select WinSrv2019-2
        ‚óã Click Identity under the Settings section
        ‚óã Set System-assigned status to On and click Save
    2. Grant Storage Permissions
        ‚óã Navigate to the Storage Account where blob data resides
        ‚óã Go to Access Control (IAM) ‚Üí + Add ‚Üí Add role assignment
        ‚óã In Role, search for and select Storage Blob Data Reader
        ‚óã In Assign access to, choose Managed identity
        ‚óã Click Select members ‚Üí find and select WinSrv2019-2
        ‚óã Click Review + assign

PowerShell:

powershell
CopyEdit
# Enable system-assigned identity
$vm = Get-AzVM -Name "WinSrv2019-2" -ResourceGroupName "App1"
$vm.Identity.Type = 'SystemAssigned'
Update-AzVM -VM $vm -ResourceGroupName "App1"
# Retrieve the identity's principal ID
$identity = (Get-AzVM -ResourceGroupName "App1" -Name "WinSrv2019-2").Identity.PrincipalId
# Assign Storage Blob Data Reader role
New-AzRoleAssignment `
  -ObjectId $identity `
  -RoleDefinitionName "Storage Blob Data Reader" `
  -Scope "/subscriptions/<subId>/resourceGroups/App1/providers/Microsoft.Storage/storageAccounts/<storageAccountName>"

Azure CLI:

bash
CopyEdit
# Enable system-assigned identity
az vm identity assign \
  --name WinSrv2019-2 \
  --resource-group App1
# Retrieve identity principal ID
principalId=$(az vm show -g App1 -n WinSrv2019-2 --query identity.principalId -o tsv)
# Assign role to identity
az role assignment create \
  --assignee $principalId \
  --role "Storage Blob Data Reader" \
  --scope "/subscriptions/<subId>/resourceGroups/App1/providers/Microsoft.Storage/storageAccounts/<storageAccountName>"


## Hardening Azure SQL Managed Instance




5. Hardening Azure SQL Managed Instance
Objective:
    ‚Ä¢ Apply foundational security controls to protect an Azure SQL Database:
        ‚óã Enable Transparent Data Encryption (TDE)
        ‚óã Turn on Microsoft Defender for Cloud
        ‚óã Configure daily backups with retention
        ‚óã Apply Dynamic Data Masking (DDM)
        ‚óã Restrict access via SQL firewall rules

Security Context / Why We Do This:
    ‚Ä¢ TDE encrypts data at rest, protecting against unauthorized access to underlying storage
    ‚Ä¢ Defender for SQL offers threat detection and vulnerability scanning
    ‚Ä¢ Firewall rules control who can connect to the SQL instance
    ‚Ä¢ DDM obfuscates sensitive data in query results without changing the underlying database
    ‚Ä¢ Backup policies ensure recoverability and regulatory compliance (e.g., HIPAA, ISO)

Key Concepts from Video:
    ‚Ä¢ SQL is often a critical asset‚Äîcustomer, financial, or health data is often stored here
    ‚Ä¢ Misconfiguration can lead to data leaks, especially when accessed from public IPs
    ‚Ä¢ Best practice: Combine platform security (TDE, firewall) with identity controls and masking
    ‚Ä¢ Defender can send alerts to Microsoft Defender for Cloud, which provides recommendations

Portal Steps:
    1. Enable Transparent Data Encryption (TDE):
        ‚óã Go to SQL databases > Select your DB (e.g., db1)
        ‚óã Under Security, click Transparent Data Encryption
        ‚óã Set to ON ‚Üí Click Save
    2. Enable Microsoft Defender for SQL:
        ‚óã Go to Microsoft Defender for Cloud > Environment settings
        ‚óã Select the subscription > SQL servers
        ‚óã Enable Microsoft Defender for SQL for your server (e.g., sqlserver01)
    3. Configure Backup Retention Policy:
        ‚óã Navigate to SQL Server > sqlserver01 > Backups
        ‚óã Set Retention policy ‚Üí Choose 24 hours (or as needed)
        ‚óã Save settings
    4. Apply Dynamic Data Masking (DDM):
        ‚óã Go to SQL databases > Select db1 > Security > Dynamic Data Masking
        ‚óã Click + Add masking rule
            ¬ß Choose sensitive column (e.g., SSN, creditCard)
            ¬ß Set masking format (e.g., default, custom string)
        ‚óã Click Add
    5. Restrict IP Access via Firewall Rules:
        ‚óã Go to SQL Server > sqlserver01 > Networking
        ‚óã Click + Add client IP or define range (e.g., 192.168.1.0/24)
        ‚óã Click Save

PowerShell:
# Enable Transparent Data Encryption
Set-AzSqlDatabaseTransparentDataEncryption `
  -ResourceGroupName "App1" `
  -ServerName "sqlserver01" `
  -DatabaseName "db1" `
  -State "Enabled"
# Enable Microsoft Defender (Threat Detection Policy)
Set-AzSqlServerThreatDetectionPolicy `
  -ResourceGroupName "App1" `
  -ServerName "sqlserver01" `
  -State Enabled
# Add firewall rule
New-AzSqlServerFirewallRule `
  -ResourceGroupName "App1" `
  -ServerName "sqlserver01" `
  -FirewallRuleName "AllowMyIP" `
  -StartIpAddress "192.168.1.1" `
  -EndIpAddress "192.168.1.1"

Azure CLI:
# Enable TDE
az sql db tde set \
  --resource-group App1 \
  --server sqlserver01 \
  --name db1 \
  --status Enabled
# Enable Defender for SQL (threat detection)
az sql server threat-policy update \
  --resource-group App1 \
  --server sqlserver01 \
  --state Enabled
# Add firewall rule
az sql server firewall-rule create \
  --resource-group App1 \
  --server sqlserver01 \
  --name AllowMyIP \
  --start-ip-address 192.168.1.1 \
  --end-ip-address 192.168.1.1


##  Encrypting Azure VM Disks


7. Configuring Time-Limited Restricted Storage Account Access
Objective:
    ‚Ä¢ Use a Shared Access Signature (SAS) token to grant temporary, IP-restricted access
    ‚Ä¢ Scope: allow read and list operations on blob containers
    ‚Ä¢ Enforce access only from a specific IP range and time window

Security Context / Why We Do This:
    ‚Ä¢ A SAS token enables granular, time-bound access to storage resources without giving full credentials
    ‚Ä¢ This is ideal for:
        ‚óã Third-party developers
        ‚óã Temporary access during migration
        ‚óã Restricting downloads/uploads to a known IP or time
    ‚Ä¢ Prevents abuse of long-lived credentials by limiting what actions are allowed, from where, and for how long
    ‚Ä¢ SAS tokens can be revoked by regenerating storage account keys

Key Concepts from Video:
    ‚Ä¢ SAS tokens support service-level permissions (Blob, File, Queue, Table)
    ‚Ä¢ You must define what, who, how long, and from where when generating a token
    ‚Ä¢ SAS URLs can be embedded in scripts, apps, or sent to external parties
    ‚Ä¢ Tip: Store SAS usage logs using Storage analytics

Portal Steps:
    1. Navigate to Storage Account
        ‚óã Go to Storage Accounts > Choose your storage (e.g., mystorageeast)
        ‚óã Under Settings, click Shared access signature
    2. Configure SAS Settings
        ‚óã Services: Select only Blob
        ‚óã Resource types: Select Container and Object
        ‚óã Permissions: Check Read and List
        ‚óã Start time: Set current date/time
        ‚óã Expiry time: Set a future date/time (e.g., 2 hours later)
        ‚óã Allowed IP addresses: Enter range (e.g., 192.168.100.0/24)
        ‚óã Allowed protocols: HTTPS only
        ‚óã Click Generate SAS and connection string
    3. Copy and Share SAS URL
        ‚óã Copy the generated SAS token or full blob URL with query string
        ‚óã Paste into browser or use in PowerShell/CLI to test

PowerShell:
# Connect to storage account context
$ctx = New-AzStorageContext -StorageAccountName "mystorageeast" -StorageAccountKey "<storageKey>"
# Generate SAS for container
New-AzStorageContainerSASToken `
  -Name "backups" `
  -Context $ctx `
  -Permission rl `
  -StartTime (Get-Date) `
  -ExpiryTime (Get-Date).AddHours(2) `
  -Protocol HttpsOnly `
  -IPAddressOrRange "192.168.100.0/24" `
  -FullUri

Azure CLI:
# Generate SAS token for container
az storage container generate-sas \
  --account-name mystorageeast \
  --name backups \
  --permissions rl \
  --expiry "$(date -u -d '2 hours' +%Y-%m-%dT%H:%MZ)" \
  --ip "192.168.100.0/24" \
  --https-only \
  --auth-mode key \
  --output tsv
    üîê Pro tip: Use the resulting SAS token in this format:
    https://mystorageeast.blob.core.windows.net/backups?<sas_token_here>

## Configuring Time-limited Restricted Storage Account Access


7. Configuring Time-Limited Restricted Storage Account Access
Objective:
    ‚Ä¢ Use a Shared Access Signature (SAS) token to grant temporary, IP-restricted access
    ‚Ä¢ Scope: allow read and list operations on blob containers
    ‚Ä¢ Enforce access only from a specific IP range and time window

Security Context / Why We Do This:
    ‚Ä¢ A SAS token enables granular, time-bound access to storage resources without giving full credentials
    ‚Ä¢ This is ideal for:
        ‚óã Third-party developers
        ‚óã Temporary access during migration
        ‚óã Restricting downloads/uploads to a known IP or time
    ‚Ä¢ Prevents abuse of long-lived credentials by limiting what actions are allowed, from where, and for how long
    ‚Ä¢ SAS tokens can be revoked by regenerating storage account keys

Key Concepts from Video:
    ‚Ä¢ SAS tokens support service-level permissions (Blob, File, Queue, Table)
    ‚Ä¢ You must define what, who, how long, and from where when generating a token
    ‚Ä¢ SAS URLs can be embedded in scripts, apps, or sent to external parties
    ‚Ä¢ Tip: Store SAS usage logs using Storage analytics

Portal Steps:
    1. Navigate to Storage Account
        ‚óã Go to Storage Accounts > Choose your storage (e.g., mystorageeast)
        ‚óã Under Settings, click Shared access signature
    2. Configure SAS Settings
        ‚óã Services: Select only Blob
        ‚óã Resource types: Select Container and Object
        ‚óã Permissions: Check Read and List
        ‚óã Start time: Set current date/time
        ‚óã Expiry time: Set a future date/time (e.g., 2 hours later)
        ‚óã Allowed IP addresses: Enter range (e.g., 192.168.100.0/24)
        ‚óã Allowed protocols: HTTPS only
        ‚óã Click Generate SAS and connection string
    3. Copy and Share SAS URL
        ‚óã Copy the generated SAS token or full blob URL with query string
        ‚óã Paste into browser or use in PowerShell/CLI to test

PowerShell:
# Connect to storage account context
$ctx = New-AzStorageContext -StorageAccountName "mystorageeast" -StorageAccountKey "<storageKey>"
# Generate SAS for container
New-AzStorageContainerSASToken `
  -Name "backups" `
  -Context $ctx `
  -Permission rl `
  -StartTime (Get-Date) `
  -ExpiryTime (Get-Date).AddHours(2) `
  -Protocol HttpsOnly `
  -IPAddressOrRange "192.168.100.0/24" `
  -FullUri

Azure CLI:
# Generate SAS token for container
az storage container generate-sas \
  --account-name mystorageeast \
  --name backups \
  --permissions rl \
  --expiry "$(date -u -d '2 hours' +%Y-%m-%dT%H:%MZ)" \
  --ip "192.168.100.0/24" \
  --https-only \
  --auth-mode key \
  --output tsv
    üîê Pro tip: Use the resulting SAS token in this format:
    https://mystorageeast.blob.core.windows.net/backups?<sas_token_here>


## Creating a Compliant Cloud Sandbox



8. Creating a Compliant Cloud Sandbox
Objective:
    ‚Ä¢ Use Azure Blueprints to deploy a secure, policy-compliant sandbox:
        ‚óã Create a resource group named Sandbox
        ‚óã Assign Contributor access to a group named App1
        ‚óã Enforce policies: SQL auditing and allowed locations (East US only)

Security Context / Why We Do This:
    ‚Ä¢ Cloud sandboxes are often used for testing, training, or staging with minimal risk to production
    ‚Ä¢ Applying RBAC + Azure Policy ensures:
        ‚óã No unauthorized role sprawl
        ‚óã Resources stay in approved locations
        ‚óã Compliance mandates (like CIS, FedRAMP) are enforced automatically
    ‚Ä¢ Blueprints support repeatable deployments, version control, and auditable governance

Key Concepts from Video:
    ‚Ä¢ Blueprints are higher-level governance tools that combine:
        ‚óã Resource templates
        ‚óã Role assignments
        ‚óã Policy assignments
    ‚Ä¢ They ensure that each new environment is built securely by design
    ‚Ä¢ Blueprint assignments are tracked and can be locked from tampering

Portal Steps:
    1. Create a Blueprint
        ‚óã Go to Azure Blueprints > Create > Start with a Blank blueprint
        ‚óã Name: CompliantSandbox
        ‚óã Assign to a Management Group or Subscription
    2. Add Artifacts to the Blueprint
        ‚óã Click Add artifact ‚Üí Select type: Resource group
            ¬ß Name: Sandbox, Location: East US
        ‚óã Add Role Assignment:
            ¬ß Role: Contributor
            ¬ß Principal: Azure AD Group App1
        ‚óã Add Policy Assignment:
            ¬ß Policy: Audit SQL server configurations
            ¬ß Policy: Allowed Locations ‚Üí Set to only allow East US
    3. Publish and Assign the Blueprint
        ‚óã Click Publish blueprint ‚Üí Add version (e.g., v1.0)
        ‚óã Click Assign blueprint
            ¬ß Select Subscription
            ¬ß Lock Assignment: Read Only or Do Not Lock
            ¬ß Enter parameter values (e.g., location = East US)
            ¬ß Click Assign

PowerShell:
    ‚ö†Ô∏è PowerShell support for Blueprints requires the Az.Blueprint module (may need manual install)
# Install module if needed
Install-Module -Name Az.Blueprint
# Define blueprint
New-AzBlueprint -Name "CompliantSandbox" -SubscriptionId <subId> -DisplayName "Compliant Cloud Sandbox"
# Add resource group artifact
New-AzBlueprintArtifact `
  -BlueprintName "CompliantSandbox" `
  -ArtifactName "SandboxRG" `
  -ResourceGroupArtifact `
  -DisplayName "Sandbox RG" `
  -ResourceGroupName "Sandbox" `
  -Location "East US"
# Assign contributor role to group
New-AzBlueprintArtifact `
  -BlueprintName "CompliantSandbox" `
  -ArtifactName "ContributorRole" `
  -RoleAssignmentArtifact `
  -DisplayName "Contributor Access" `
  -PrincipalId <GroupObjectId> `
  -RoleDefinitionId "/subscriptions/<subId>/providers/Microsoft.Authorization/roleDefinitions/<ContributorRoleId>"
# Assign the blueprint
Set-AzBlueprintAssignment -Name "CompliantSandbox" -SubscriptionId <subId>

Azure CLI:
    ‚ùå Azure CLI does not support Blueprints natively.
    ‚úÖ Use ARM templates or REST API for automation.
    ‚öôÔ∏è Workaround CLI path: deploy equivalent with az deployment sub create and policy assignments:
# Assign 'Allowed Locations' policy manually
az policy assignment create \
  --name "LimitLocations" \
  --policy "b24988ac-6180-42a0-ab88-20f7382dd24c" \
  --params '{ "listOfAllowedLocations": { "value": [ "eastus" ] } }' \
  --scope "/subscriptions/<subId>"
# Assign 'Audit SQL configurations'
az policy assignment create \
  --name "AuditSQL" \
  --policy "0e3a6b26-1e2e-4b6b-89f3-4b61b6359c79" \
  --scope "/subscriptions/<subId>"

## Generating Key Vault Secrets

9. Generating Key Vault Secrets
Objective:
In Key Vault KVCentral, you will:
    ‚Ä¢ Store a database connection string as a secret
    ‚Ä¢ Generate a self-signed certificate named WebApp1 with subject CN=www.webapp1.local
    ‚Ä¢ Create an encryption key (Key1) using RSA 2048-bit key

Security Context / Why We Do This:
    ‚Ä¢ Key Vault is a centralized tool to securely manage:
        ‚óã Secrets: passwords, connection strings, API keys
        ‚óã Keys: encryption keys for services like SQL TDE, VM disk encryption
        ‚óã Certificates: SSL/TLS for websites and apps
    ‚Ä¢ Avoids hardcoding secrets in source code or storing them in unsecured files
    ‚Ä¢ Supports RBAC and access policies, plus full audit logging and integration with Managed Identity

Key Concepts from Video:
    ‚Ä¢ Never store secrets in plain text or local config files ‚Äî always use Key Vault
    ‚Ä¢ Certificates can be self-signed or issued by a CA (e.g., DigiCert, Sectigo)
    ‚Ä¢ Keys can be used in services like Disk Encryption, Azure SQL, or Custom Apps
    ‚Ä¢ Access is tightly controlled with role-based access or legacy access policies

Portal Steps:
    1. Create a Key Vault (if needed):
        ‚óã Azure Portal > Key Vaults > + Create
        ‚óã Name: KVCentral
        ‚óã Resource group: App1
        ‚óã Region: Central US
        ‚óã Pricing tier: Standard
        ‚óã Enable soft-delete and RBAC permissions model
    2. Add a Secret:
        ‚óã Navigate to KVCentral > Secrets > + Generate/Import
        ‚óã Upload method: Manual
        ‚óã Name: DBConnectionString1
        ‚óã Value: Server=sqlserver01;Database=appdb;User Id=admin;Password=SecureP@ssw0rd
        ‚óã Click Create
    3. Create a Key:
        ‚óã Navigate to KVCentral > Keys > + Generate
        ‚óã Name: Key1
        ‚óã Key type: RSA
        ‚óã RSA key size: 2048
        ‚óã Click Create
    4. Create a Certificate:
        ‚óã Navigate to KVCentral > Certificates > + Generate/Import
        ‚óã Method: Generate
        ‚óã Name: WebApp1
        ‚óã Certificate Type: Self-signed
        ‚óã Subject: CN=www.webapp1.local
        ‚óã Validity: 12 months (default)
        ‚óã Click Create

PowerShell:
# Create a Key Vault (if needed)
New-AzKeyVault -Name "KVCentral" -ResourceGroupName "App1" -Location "Central US"
# Add a secret
Set-AzKeyVaultSecret `
  -VaultName "KVCentral" `
  -Name "DBConnectionString1" `
  -SecretValue (ConvertTo-SecureString "Server=sqlserver01;Database=appdb;User Id=admin;Password=SecureP@ssw0rd" -AsPlainText -Force)
# Create a software-protected key
Add-AzKeyVaultKey `
  -VaultName "KVCentral" `
  -Name "Key1" `
  -Destination "Software"
# Create a self-signed certificate
$policy = Get-AzKeyVaultCertificatePolicy -SubjectName "CN=www.webapp1.local"
Add-AzKeyVaultCertificate `
  -VaultName "KVCentral" `
  -Name "WebApp1" `
  -Policy $policy

Azure CLI:
# Create Key Vault
az keyvault create \
  --name KVCentral \
  --resource-group App1 \
  --location "centralus"
# Add secret
az keyvault secret set \
  --vault-name KVCentral \
  --name DBConnectionString1 \
  --value "Server=sqlserver01;Database=appdb;User Id=admin;Password=SecureP@ssw0rd"
# Create key
az keyvault key create \
  --vault-name KVCentral \
  --name Key1 \
  --protection software \
  --kty RSA \
  --size 2048
# Create certificate
az keyvault certificate create \
  --vault-name KVCentral \
  --name WebApp1 \
  --policy "$(az keyvault certificate get-default-policy --subject 'CN=www.webapp1.local')"
